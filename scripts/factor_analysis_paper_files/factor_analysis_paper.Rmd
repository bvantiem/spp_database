---
title: "Final Project"
author: "Britte van Tiem"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    number_sections: yes
    theme: lumen
    toc: yes
    toc_depth: 4
    toc_float: yes
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: '4'
  word_document:
    toc: yes
    toc_depth: '4'
urlcolor: blue
editor_options: 
  chunk_output_type: console #inline
always_allow_html: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = 'center')
#knitr::opts_chunk$set(echo = TRUE, fig.width=8, fig.height=4)
options(scipen = 0, digits = 3) 
if(!require('pacman')) {
  install.packages('pacman')
}
pacman::p_load(tidyverse, dplyr, readxl, tidyverse, naniar, xtable, splithalf, mice, ggmice, psych, missForest, nlme, texreg, lubridate)
`%ni%` = Negate(`%in%`)
set.seed(1234)
```


\tableofcontents

# Data Set up 
## Create Keys for hypothesized scales 
```{r Keys for hypothesized scales}
scale.hyp.key <- list(prisoners = c("q10", "q11", "q12", "q13", "q14") ,
                  staff = c("q15", "q16", "q17", "q18"),
                  procedure = c("q19", "q20", "q21", "q22"),
                  safety = c("q26", "q29", "q30", "q31", "q32"),
                  visits = c("q139","q140", "q141", "q142", "q143", "q144", "q145", "q146"),
                  contact = c("q135", "q136", "q137"),
                  sleep = c("q94", "q95", "q96"),
                  care = c("q111", "q112", "q119", "q120", "q121", "q122"),
                  shop = c("q99", "q100", "q101"),
                  actsat = c("q62", "q63", "q64", "q65", "q66", "q67", "q68"),
                  actav = c("q69", "q70", "q71", "q72"), 
                  reint = c("q73", "q74", "q75", "q76") ,
                  autonomy = c("q82", "q83", "q84", "q85"))

scale_names <- data.frame(scale_abbreviation = names(scale.hyp.key),
                          scale_theory_long = c("1. Prisoner relationships",
                                                "2. Staff-prisoner relationships",
                                                "3. Procedural Justice",
                                                "4. Safety",
                                                "5. Satisfaction with Visits",
                                                "6. Satisfaction With Frequency of Contact",
                                                "7. Sleep Quality",
                                                "8. Quality of care",
                                                "9. Shop Quality",
                                                "10. Satisfaction with Activities",
                                                "11. Availability of Meaningful Activities",
                                                "12. Reintegration",
                                                "13. Autonomy"))
```

```{r Load data and set up}
load("data/processed/pcq.Rda")
load("data/processed/pcq2.Rda")
load("data/processed/basic.Rda")
pcq_lookup <- read_xlsx("data/raw/230207_pcq_survey_questions_NL_PA.xlsx")

pcq_lookup <- pcq_lookup %>%
  mutate(question_qno = paste0("q", question_no_pa_2022a), .after = question_no_pa_2022a)
pcq_lookup <- as.data.frame(pcq_lookup)

# Subset data to analysis based on wave 1 alone
pcq <- pcq[which(pcq$survey_wave==1),]

# Because this has just 1 individual in there, generates issues with regressions 
pcq <- pcq[pcq$unit_type!="inf",]

# Delete individuals who completed the survey for a second time within wave one.
# HANDCODED
pcq <- pcq[-which(pcq$research_id=="rid_ap7756" & pcq$date=="2022_05_06"),]
pcq <- pcq[-which(pcq$research_id=="rid_eu8244" & pcq$date=="2022_05_02"),]
pcq <- pcq[-which(pcq$research_id=="rid_at6697" & is.na(pcq$date)),]

# save full dataset
pcq_full <- pcq

# Retain only questions needed for psychometrics analysis
retain <- unique(unlist(scale.hyp.key))
pcq <- pcq[,retain]
```

```{r create pcq2}
# pcq & pcq2 - to distinguish responses that are complete but may include 'no opinion' or 'not applicable' answers, from cases that have missing data (999)
# pcq - 999 is set to NA, no opinion = 111, not applicable = 996
# pcq2 - 999, 111, and 996 are all set to NA

pcq2 <- pcq
pcq2 <- pcq2 %>% replace_with_na_all(condition = ~.x == 111)
pcq2 <- pcq2 %>% replace_with_na_all(condition = ~.x == 996)
```

## Missing data 
```{r Drop data from individuals with more than 10 missing answers, include=FALSE}
tail(sort(rowSums(is.na(pcq))), n=15) # use pcq because it doesn't count 'no opinion' answers as missing
# Drop individuals with more than 10 missing answers
i <- which(rowSums(is.na(pcq))>=10)
pcq <- pcq[-i,]
pcq2 <- pcq2[-i,]
pcq_full <- pcq_full[-i,]
```

```{r Missing Data Table, results='asis'}
# Missing data table
tab <- data.frame(question = pcq_lookup[pcq_lookup$question_qno %in% names(pcq[,1:ncol(pcq)]),"question_pa_2022a"],
                  question_qno = pcq_lookup[pcq_lookup$question_qno %in% names(pcq[,1:ncol(pcq)]),"question_qno"],
                  domain = pcq_lookup[pcq_lookup$question_qno %in% names(pcq[,1:ncol(pcq)]),"domain_no_bosma"],
                  scale = pcq_lookup[pcq_lookup$question_qno %in% names(pcq[,1:ncol(pcq)]),"scale_theory_long"],
                  missing = NA,
                  no_opinion = NA)
for(i in names(pcq[which(rowSums(is.na(pcq))<=10),1:ncol(pcq)])){
  tab[tab$question_qno==i,"missing"] <- length(which(is.na(pcq[,i])))
  tab[tab$question_qno==i,"no_opinion"] <- length(which(pcq[,i]==111))
}
tab <- tab[order(tab$domain),c("scale","question", "missing", "no_opinion")]
names(tab) <- c("Scale","Item","Missing", "No Opinion")
tab$Scale[which(tab$Scale=="Satisfaction with Frequency of Contact")] <- "Frequency of Contact"
print(xtable(tab, digits=c(0,0,0,0,0), caption="Missingness by Item"), include.rownames = FALSE, type="html",caption.placement="top", file="output/tables/missingness.txt")

print(xtable(tab, digits=c(0,0,0,0,0), caption="Missingness by Item"), include.rownames = FALSE, ,caption.placement="top", file="output/tables/missingness.txt")

```

## "No opinion" Patterns 

```{r missing data plots}
pcq3 <- pcq
pcq3 <- as.data.frame(pcq3)
for(i in names(pcq3)){
k <- which(is.na(pcq3[,i]))
pcq3[k,i]  <- 999
b <- which(pcq3[,i]==111)
pcq3[b,i] <- NA
}

# Visits 
vars <- paste0("q", seq(139,146,1))
temp <- pcq3[,vars]
names(temp) <- c("visiting_room", "physical_contact", "length", "privacy","visitor_treatment", "frequency", "enjoy_visits", "feel_good")
# https://amices.org/ggmice/reference/plot_pattern.html
temp <- as_tibble(temp)
p <- plot_pattern(
  temp,
  vrb = "all") +
  ggtitle("Missing Data distribution for items on the Visits Scale")
gg_miss_upset(temp, nsets=8)

ggsave("output/figures/missing_data_visits.jpg", plot = p, width = 6, height = 4, dpi = 300)
# Satisfaction with Activities
vars <- paste0("q", seq(62,68,1))
temp <- pcq3[,vars]
names(temp) <- c("recreation", "sports", "library", "work", "education", "outdoor", "religious_services")
# https://amices.org/ggmice/reference/plot_pattern.html
p <- plot_pattern(
  temp,
  vrb = "all") +
  ggtitle("Missing Data distribution for items on the Satisfaction with Activities Scale")

ggsave("output/figures/missing_data_activities.jpg", plot = p, width = 6, height = 4, dpi = 300)

# Quality of Care
# Note: q111 and 112 also belong to this scale (on access and adequate care) but they do not have a no opinion option 
vars <- paste0("q", seq(119,122,1))
temp <- pcq3[,vars]
names(temp) <- c("doctor", "nurse", "dentist", "psychologist")
# https://amices.org/ggmice/reference/plot_pattern.html
p <- plot_pattern(
  temp,
  vrb = "all") +
  ggtitle("Missing Data distribution for items on the Quality of Care Scale")

ggsave("output/figures/missing_data_care.jpg", plot = p, width = 6, height = 4, dpi = 300)
```

The survey includes questions about individuals' service use in the past month. The barplots below show that the likelihood of 'no opinion' responses are indeed related to use of these services in the past month. Formal tests (not displayed here) show that these relationships are highly significant.  

```{r, eval=FALSE}
# Visits - visiting room is pleasant 
pcq_full$q138_dummy <- ifelse(pcq_full$q138=="1",0,1)
pcq_full$q139_dummy <- ifelse(pcq_full$q139=="111", 1,0)

pcq_full$q139_dummy <- ifelse(pcq_full$q139_dummy=="1", "No Opinion", "Question Answered")
pcq_full$q138_dummy <- ifelse(pcq_full$q138_dummy=="1", "Yes", "No")
ggplot(pcq_full[which(!is.na(pcq_full$q138_dummy) & !is.na(pcq_full$q139_dummy)),], aes(x = as.factor(q138_dummy), fill = q139_dummy)) + geom_bar(position="dodge") + 
  xlab("Received a Visit in the past month") +
  ylab("The visiting room is pleasant") +
  theme_bw() +
  theme(legend.title=element_blank())


# Psychologist 
pcq_full$q118_dummy <- ifelse(pcq_full$q118=="1", 0,1)
pcq_full$q122_dummy <- ifelse(pcq_full$q122=="111", 1,0)

pcq_full$q122_dummy <- ifelse(pcq_full$q122_dummy=="1", "No Opinion", "Question Answered")
pcq_full$q118_dummy <- ifelse(pcq_full$q118_dummy=="1", "Yes", "No")
ggplot(pcq_full[which(!is.na(pcq_full$q118_dummy) & !is.na(pcq_full$q122_dummy)),], aes(x = as.factor(q118_dummy), fill = q122_dummy)) + 
  geom_bar(position="dodge") + 
  xlab("Seen Psychologist in past month") +
  ylab("Satisfied with the work of \n the Psychologist")+
  theme_bw()+
  theme(legend.title=element_blank()) 

# Library
pcq_full$q57_dummy <- ifelse(pcq_full$q57=="1", 0,1)
pcq_full$q64_dummy <- ifelse(pcq_full$q64=="111", 1,0)

pcq_full$q64_dummy <- ifelse(pcq_full$q64_dummy=="1", "No Opinion", "Question Answered")
pcq_full$q57_dummy <- ifelse(pcq_full$q57_dummy=="1", "Yes", "No")
ggplot(pcq_full[which(!is.na(pcq_full$q57_dummy) & !is.na(pcq_full$q64_dummy)),], aes(x = as.factor(q57_dummy), fill = q64_dummy)) + 
  geom_bar(position="dodge") + 
  xlab("Used Library in past month") +
  ylab("Satisfied with the Library")+
  theme_bw()+
  theme(legend.title=element_blank()) 
```

## Create Datasets
```{r create datasets for factor analysis, include = FALSE}
# Dataset 0: all items, for use with pairwise deletion in factor analysis ####
# Dataset 1: all items, complete cases ####
pcq2_cc <- pcq2[complete.cases(pcq2),] # 276 cases 
pcq2_cc <- cbind(pcq2_cc, scoreItems(scale.hyp.key, pcq2_cc)$scores)

# Dataset 2: scales with missing data imputed using Random forest####
# https://academic-oup-com.proxy.library.upenn.edu/bioinformatics/article/28/1/112/219101?login=true&token=
# Impute based on service use variables

pcq_full <- as.data.frame(pcq_full)
service_use_qs <- c("q55","q56","q57","q58","q59","q61","q115","q116","q117","q118","q138" ,"q167", "q162", "q163")
pcq2_service_use <- pcq_full[,service_use_qs]
# pcq_lookup[pcq_lookup$question_qno %in% service_use_qs, c("question_qno", "question_pa_2022a")]
pcq2_of <- as.data.frame(pcq2)
pcq_of <- cbind(pcq2_of, pcq2_service_use)

for(i in names(pcq2_of)){
  pcq2_of[,i] <- as.factor(pcq2_of[,i])
}
pcq2_imp <- missForest(pcq2_of)
pcq2_of <- pcq2_imp$ximp
rm(pcq2_imp)

# Because fa.parallel needs numeric data
for(i in names(pcq2_of)){
  pcq2_of[,i] <- as.numeric(pcq2_of[,i])
}
pcq2_of <- cbind(pcq2_of, scoreItems(scale.hyp.key, pcq2_of)$scores)
```

# Table with questions in both surveys ####
```{r}
pcq_lookup$question_no_nl_2017 <- as.numeric(pcq_lookup$question_no_nl_2017)
tab <- pcq_lookup[which(pcq_lookup$question_qno %in% unlist(scale.hyp.key)),c("part_nl_2017","question_no_nl_2017","question_nl_2017", "question_no_pa_2022a", "question_pa_2022a", "scale_theory")]
names(tab)[which(names(tab)=="scale_theory")] <- "scale_abbreviation"
tab <- left_join(tab, scale_names)
tab <- tab %>% group_by(part_nl_2017)
tab <- tab %>% arrange(question_no_nl_2017, .by_group = TRUE)
tab$question_no_nl_2017 <- paste0(tab$part_nl_2017, tab$question_no_nl_2017)
tab <- tab[,-which(names(tab) %in% c("part_nl_2017", "scale_abbreviation", "scale_theory_long"))]
print(xtable(tab, digits=0), caption="Questionnaire Items and their Positioning, in NL and PA surveys", 
      include.rownames = FALSE, 
      caption.placement="top",
      file = "output/tables/items_and_positioning.txt")
```




# Bosma Replication ####
```{r Reliability Table, include=FALSE}
library(ltm)
keep0 <- data.frame(scale = names(scale.hyp.key),
                    items = rep("boo", length(scale.hyp.key)),
                    mean = rep("boo", length(scale.hyp.key)),
                    sd = rep("boo", length(scale.hyp.key)),
                    cr.alpha = rep("boo", length(scale.hyp.key)),
                    sb.stat = rep("boo", length(scale.hyp.key)),
                    sb_low = rep("boo", length(scale.hyp.key)),
                    sb_high = rep("boo", length(scale.hyp.key)))


# Cannot be run for pairwise deletions because no way to 'score scales' with pairwise deletions. ####
dataset.choice <- list(data1 = pcq2_cc,
                       data2 = pcq2_of)
results <- list(data1 = NA,
                data2 = NA)

for(s in 1:length(dataset.choice)){
keep <- keep0
for(i in names(scale.hyp.key)){
  # Populate table ####  
  k <- which(keep$scale==i)
  keep[k, "items"] <- length(scale.hyp.key[[i]])
  keep[k, "mean"] <- mean(dataset.choice[[s]][,i])
  keep[k, "sd"] <- sd(dataset.choice[[s]][,i])
  keep[k, "cr.alpha"] <- alpha(dataset.choice[[s]][,scale.hyp.key[[i]]])[[1]][1]
  
  # Calculate Splithalf values if scale length is greater than 3 ####
  if(length(scale.hyp.key[[i]])>3){
    temp <- dataset.choice[[s]][,scale.hyp.key[[i]]] 
    temp <- cbind(temp, research_id = seq(1,nrow(temp),1))
    temp <- reshape(data = temp, idvar="research_id",
                    varying = scale.hyp.key[[i]],
                    v.name=c("RT"),
                    times = scale.hyp.key[[i]],
                    direction="long")
    names(temp) <- c("research_id", "trial_number", "RT")
    
    sb.stat <- splithalf(data = temp,
                         outcome = "RT",
                         score = "average", 
                         halftype = "random", 
                         permutations = 1000, 
                         var.RT = "RT",
                         var.participant = "research_id",
                         average = "mean",
                         plot = FALSE)
    
    keep[k, c("sb.stat", "sb_low", "sb_high")] <- sb.stat$final_estimates[,c("spearmanbrown", "SB_low", "SB_high")]
  }
  }
results[[s]] <- keep
}
```

```{r print table html reliability}
knitr::kable(results[[1]])
knitr::kable(results[[2]])

tab <- results[[1]]
i <- match(tab$scale, scale_names$scale_abbreviation)
tab$scale <- scale_names$scale_theory_long[i]
names(tab) <- c("Scale","Items","Mean", "SD", "CA","SB", "SB Lower", "SB Upper")
for(i in c("Mean", "SD", "CA","SB", "SB Lower", "SB Upper")){
  tab[,i] <- as.numeric(tab[,i])
}
print(xtable(tab, digits=c(0,0,0,2,2,2,2,2,2), caption="Reliability Analysis"), 
      include.rownames = FALSE, 
      caption.placement="top",
      file = "output/tables/reliability.txt")

tab <- results[[2]]
i <- match(tab$scale, scale_names$scale_abbreviation)
tab$scale <- scale_names$scale_theory_long[i]
names(tab) <- c("Scale","Items","Mean", "SD", "CA","SB", "SB Lower", "SB Upper")
for(i in c("Mean", "SD", "CA","SB", "SB Lower", "SB Upper")){
  tab[,i] <- as.numeric(tab[,i])
}
print(xtable(tab, digits=c(0,0,0,2,2,2,2,2,2), caption="Reliability Analysis"), 
      include.rownames = FALSE, 
      caption.placement="top",
      file = "output/tables/reliability_appendix.txt")
```

```{r InterScale Correlation Table}
dataset.choice <- list(data1 = pcq2_cc,
                       data2 = pcq2_of)
results <- list(data1 = NA,
                data2 = NA)

n_scales <- length(unique(scale.hyp.key))

for(s in 1:length(dataset.choice)){
  my.scores <- scoreItems(scale.hyp.key,
                          dataset.choice[[s]],
                          missing=FALSE) 
  
  # Retain only the corrected correlations (above the diagonal)
    keep <- t(as.vector(c(rep(0,1),rep(1,n_scales-1))))
    for(i in 2:n_scales){
      keep <- rbind(keep,t(as.vector(c(rep(0,i), rep(1,n_scales-i)))))
    }
    tab <- t(as.data.frame(my.scores$corrected*keep))
    tab[which(tab==0)] <- ""
    tab <- as.data.frame(tab)
    tab <- tab[1:12]
    tab <- as.data.frame(lapply(tab,as.numeric)) # convert all columns to numeric
    names(tab) <- seq(1,n_scales-1,1)
    row.names(tab) <- scale_names$scale_theory_long[-14] # hand coded! 
    
    results[[s]] <- tab
}
```

```{r table html interscale}
knitr::kable(results[[1]])
knitr::kable(results[[2]])

print(xtable(results[[1]], digits=c(0,rep(3,12)), caption="Interscale Correlation Matrix"),
        include.rownames=TRUE, 
        caption.placement="top",
        file = "output/tables/interscale_correlation.txt")

print(xtable(results[[1]], digits=c(0,rep(3,12)), caption="Interscale Correlation Matrix"),
        include.rownames=TRUE, 
        caption.placement="top",
        file = "output/tables/interscale_correlation_appendix.txt")
 

```

```{r Unit means, include=FALSE}
dataset.choice <- list(data1 = pcq2_cc,
                       data2 = pcq2_of)
results <- list(data1 = NA,
                data2 = NA)

for(s in 1:length(dataset.choice)){
dat <- dataset.choice[[s]][,names(scale.hyp.key)]

if(names(dataset.choice)[s]=="data1"){
tab <- describeBy(dat, group = pcq_full[complete.cases(pcq2),]$unit_type, digits=2, mat=TRUE)
}

if(names(dataset.choice)[s]=="data2"){
  tab <- describeBy(dat, group = pcq_full$unit_type, digits=2, mat=TRUE)
}


tab <- tab[tab$group1!="inf",]
tab$scale_theory <- rownames(tab) # get scale names 
tab$scale_theory <- substr(tab$scale_theory, 1, nchar(tab$scale)-1)
tab <- tab[,c("mean", "group1", "scale_theory")]
tab <- reshape(tab, idvar = "scale_theory", timevar = "group1", direction = "wide", times = )
names(tab) <- gsub("mean.", "", names(tab))
i <- match(tab$scale_theory, scale_names$scale_abbreviation)
tab$scale_theory <- scale_names$scale_theory_long[i]
tab <- tab %>%  
  dplyr::select(-ls) 
names(tab) <- c("Scale", "General", "Therapeutic", "Honor", "Recovery", "Restrictive", "Transitional")
results[[s]] <- tab

file.name <- paste0("output/tables/unit_means_", names(dataset.choice[s]), ".txt")
print(xtable(tab, digits = c(0,0,rep(2,6))), include.rownames = FALSE, file = file.name)

# Calculate significant differences for superscript
if(names(dataset.choice)[s]=="data1"){
dat <- cbind(dataset.choice[[s]], unit_type = pcq_full[complete.cases(pcq2),]$unit_type)
}

if(names(dataset.choice)[s]=="data2"){
  dat <- cbind(dataset.choice[[s]], unit_type = pcq_full$unit_type)
}


dat <- dat[which(dat$unit_type != "ls"),]
for(i in names(scale.hyp.key)){
  print(i)
  lminput <- as.formula(paste(i, "~ unit_type")) 
  print(TukeyHSD(aov(lminput, dat = dat)))
  print("---------------------------------")
}

# Heat map of means 
dat <- tab %>%
  pivot_longer(!Scale, names_to = "Unit", values_to = "Mean")
p <- ggplot(dat, aes(x = Unit, y = Scale, fill = Mean)) +
  geom_tile(color = "black") +
  geom_text(aes(label = Mean), color = "black", size = 3) +
  scale_fill_gradient(low = "blue", high = "white") +
  coord_fixed(ratio = .3)+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        legend.position = "none")

file.name <- paste0("output/figures/unit_means_", names(dataset.choice[s]), ".jpg")
ggsave(file.name, plot = p, width = 9, height = 6, dpi = 300)
}

```

```{r print html unit means}
knitr::kable(results[[1]])
knitr::kable(results[[2]])
```

```{r Criterion Validity, include=FALSE}
dataset.choice <- list(data1 = pcq2_cc,
                       data2 = pcq2_of)
results <- list(data1 = NA,
                data2 = NA)

for(s in 1:length(dataset.choice)){
  # Data
  basic_temp <- basic[which(basic$research_id %in% unique(pcq_full$research_id) &
                              basic$date_datapull %in% c(ymd(20220625), ymd(20220903))),]
  
  # Deduplicate for individuals for whom I have data from both datapulls 
  basic_temp$pull_no <- 1
  temp <- data.frame(table(basic_temp$research_id))
  index <- temp[temp$Freq>1,"Var1"]
  basic_temp[basic_temp$research_id %in% index & basic_temp$date_datapull==ymd(20220903),"pull_no"] <- 2 
  basic_temp <- basic_temp[which(basic_temp$pull_no==1),] # Drops data from the second datapull on these individiduals 
  
  # Imputed data
  file.name <- paste0("output/tables/criterion_validity_", names(dataset.choice)[s], ".txt")
  
  if(names(dataset.choice)[s]=="data1"){
    dat <- cbind(dataset.choice[[s]][,names(scale.hyp.key)],
                 pcq_full[complete.cases(pcq2),c("research_id", "children", "cell", "foreign_born", "partner", "q1", "q4")])
  }
  
  if(names(dataset.choice)[s]=="data2"){
  dat <- cbind(dataset.choice[[s]][,names(scale.hyp.key)],
               pcq_full[,c("research_id", "children", "cell", "foreign_born", "partner", "q1", "q4")])
  }
  
  data.reg <- left_join(dat,basic_temp) # pcq2_full
  data.reg <- data.reg[which(data.reg$race_code != "A"),] # just two individuals, cause regression not to run 
  data.reg$est_months_served_on_20220501 <- data.reg$est_days_served_on_20220501/30.5
  # Merge in severity scale scores. Note these are NOT imputed on purpose 
  if(names(dataset.choice)[s]=="data1"){
    temp <- left_join(data.reg[,c("research_id", "cell")], pcq_full[complete.cases(pcq2), c("research_id","q7", "q8", "q9")])
  }
  
  if(names(dataset.choice)[s]=="data2"){
  temp <- left_join(data.reg[,c("research_id", "cell")], pcq_full[, c("research_id","q7", "q8", "q9")])
  }
  
  scale.sev.key <- list(severity = c("q7", "q8", "q9"))
  data.reg <- cbind(data.reg, scoreItems(scale.sev.key, temp)$scores)
  
  # Set independent variables for both regressions
  regressors <- names(scale.hyp.key)
  indvars.controls <- data.reg %>% dplyr::select(age_on_20220501, foreign_born, high_school, partner, children, est_months_served_on_20220501, race_code, cell, asca)
  indvars.controls.scales <- data.reg %>% dplyr::select(all_of(regressors), age_on_20220501, foreign_born, high_school, partner, children, est_months_served_on_20220501, race_code, cell, asca)
  
  # Depvar: I am satisfied with this insitutiton 
  fit.controls.inst <- lm(data.reg$q1 ~ ., data=indvars.controls)
  fit.controls.scales.inst <- lm(data.reg$q1 ~ ., data=indvars.controls.scales)
  summary(fit.controls.inst)$adj.r.squared
  summary(fit.controls.scales.inst)$adj.r.squared
  
  
  # Depvar: Severity Scale 
  fit.controls.sev <- lm(data.reg$severity ~ ., data=indvars.controls)
  fit.controls.scales.sev <- lm(data.reg$severity ~ ., data=indvars.controls.scales)
  summary(fit.controls.sev)$adj.r.squared
  summary(fit.controls.scales.sev)$adj.r.squared
  
  # Table
  texreg(list(fit.controls.scales.inst, fit.controls.scales.sev),
         include.ci = FALSE,
         caption="Criterion Validity",
         caption.above=TRUE,
         custom.coef.map = list("prisoners" = "Prisoner Relationships",
                                "staff" = "Staff-Prisoner Relationships",
                                "procedure" = "Procedural Justice",
                                "safety" = "Safety",
                                "visits" = "Satisfaction with Visits",
                                "contact" = "Frequency of Contact",
                                "sleep" = "Sleep quality",
                                "care" = "Quality of Care",
                                "shop" = "Shop quality",
                                "actsat" = "Satisfaction with Activities",
                                "actav" = "Availability of Activities",
                                "reint" = "Reintegration",
                                "autonomy" = "Autonomy",
                                "age_on_20220501" = "Age",
                                "foreign_born" = "Foreign Born",
                                "high_school" = "Finished High School",
                                "partner" = "Has Partner",
                                "children" = "Has Children",
                                "est_months_served_on_20220501" = "Time Served (months)",
                                "race_codeB" = "Black",
                                "cell" = "Shares a cell",
                                "asca2-Property" = "Property Offense (ref = violent)",
                                "asca3-Drugs" = "Drugs Offense (ref = violent)",
                                "asca4-Public Order" = "Public Order Offense (ref = violent)"),
         custom.header=list("Institution" = 1,
                            "Subjective Severity" = 2),
         custom.model.names = c("(1)", "(2)"),
         digits=3,
         stars = c(0.001, 0.01, 0.05),
         column.spacing = 0,
         custom.note = "Notes: Standard errors in parentheses. %stars ",
         file=file.name)
}

# Replicate with units included, offense type excluded ####
# From 0_utils because Rmd doesn't seem to work with source 
unit_mapping <- data.frame(unit = c("aa", "ab", "ac", "ad", "eb", "da", "db",
                                      "ba","bb", "bc", "bd",
                                      "ca", "cb",
                                      "ea",
                                      "rhu","fa",
                                      "inf","ma",
                                      "2a", "2a3", "2a2", "2a5", "2a6"))

unit_mapping$unit_type_nols <- with(unit_mapping, ifelse(unit %in% c("aa", "ab", "ac", "ad", "eb", "da", "db", "ca"), "gp",
                                                    ifelse(unit %in% c("bb", "bc", "bd"), "gp-tc",
                                                           ifelse(unit=="ba", "rec",
                                                                         ifelse(unit=="cb", "hons",
                                                                                ifelse(unit=="ea", "thu",
                                                                                       ifelse(unit %in% c("rhu","fa"), "rhu",
                                                                                              ifelse(unit %in% c("inf","ma"), "inf",NA))))))))


pcq_full <- left_join(pcq_full, unit_mapping)

for(s in 1:length(dataset.choice)){
  # Data
  basic_temp <- basic[which(basic$research_id %in% unique(pcq_full$research_id) &
                              basic$date_datapull %in% c(ymd(20220625), ymd(20220903))),]
  
  # Deduplicate for individuals for whom I have data from both datapulls 
  basic_temp$pull_no <- 1
  temp <- data.frame(table(basic_temp$research_id))
  index <- temp[temp$Freq>1,"Var1"]
  basic_temp[basic_temp$research_id %in% index & basic_temp$date_datapull==ymd(20220903),"pull_no"] <- 2 
  basic_temp <- basic_temp[which(basic_temp$pull_no==1),] # Drops data from the second datapull on these individiduals 
  
  # Imputed data
  file.name <- paste0("output/tables/criterion_validity_wunit_", names(dataset.choice)[s], ".txt")
  
  if(names(dataset.choice)[s]=="data1"){
    dat <- cbind(dataset.choice[[s]][,names(scale.hyp.key)],
                 pcq_full[complete.cases(pcq2),c("research_id", "children", "cell", "foreign_born", "partner", "q1", "q4", "unit_type_nols")])
  }
  
  if(names(dataset.choice)[s]=="data2"){
    dat <- cbind(dataset.choice[[s]][,names(scale.hyp.key)],
                 pcq_full[,c("research_id", "children", "cell", "foreign_born", "partner", "q1", "q4", "unit_type_nols")])
  }
  
  data.reg <- left_join(dat,basic_temp) # pcq2_full
  data.reg <- data.reg[which(data.reg$race_code != "A"),] # just two individuals, cause regression not to run 
  data.reg$est_months_served_on_20220501 <- data.reg$est_days_served_on_20220501/30.5
  # Merge in severity scale scores. Note these are NOT imputed on purpose 
  if(names(dataset.choice)[s]=="data1"){
    temp <- left_join(data.reg[,c("research_id", "cell")], pcq_full[complete.cases(pcq2), c("research_id","q7", "q8", "q9", "unit")])
  }
  
  if(names(dataset.choice)[s]=="data2"){
    temp <- left_join(data.reg[,c("research_id", "cell")], pcq_full[, c("research_id","q7", "q8", "q9")])
  }
  
  scale.sev.key <- list(severity = c("q7", "q8", "q9"))
  data.reg <- cbind(data.reg, scoreItems(scale.sev.key, temp)$scores)
  
  # Set independent variables for both regressions
  regressors <- names(scale.hyp.key)
  indvars.controls <- data.reg %>% dplyr::select(age_on_20220501, foreign_born, high_school, partner, children, est_months_served_on_20220501, race_code, cell, unit_type_nols)
  indvars.controls.scales <- data.reg %>% dplyr::select(all_of(regressors), age_on_20220501, foreign_born, high_school, partner, children, est_months_served_on_20220501, race_code, cell, unit_type_nols)
  
  # Depvar: I am satisfied with this insitutiton 
  fit.controls.inst <- lm(data.reg$q1 ~ ., data=indvars.controls)
  fit.controls.scales.inst <- lm(data.reg$q1 ~ ., data=indvars.controls.scales)
  summary(fit.controls.inst)$adj.r.squared
  summary(fit.controls.scales.inst)$adj.r.squared
  
  # Depvar: Severity Scale 
  fit.controls.sev <- lm(data.reg$severity ~ ., data=indvars.controls)
  fit.controls.scales.sev <- lm(data.reg$severity ~ ., data=indvars.controls.scales)
  summary(fit.controls.sev)$adj.r.squared
  summary(fit.controls.scales.sev)$adj.r.squared
  
  # Table
  texreg(list(fit.controls.scales.inst, fit.controls.scales.sev),
         include.ci = FALSE,
         caption="Criterion Validity",
         caption.above=TRUE,
         custom.coef.map = list("prisoners" = "Prisoner Relationships",
                                "staff" = "Staff-Prisoner Relationships",
                                "procedure" = "Procedural Justice",
                                "safety" = "Safety",
                                "visits" = "Satisfaction with Visits",
                                "contact" = "Frequency of Contact",
                                "sleep" = "Sleep quality",
                                "care" = "Quality of Care",
                                "shop" = "Shop quality",
                                "actsat" = "Satisfaction with Activities",
                                "actav" = "Availability of Activities",
                                "reint" = "Reintegration",
                                "autonomy" = "Autonomy",
                                "age_on_20220501" = "Age",
                                "foreign_born" = "Foreign Born",
                                "high_school" = "Finished High School",
                                "partner" = "Has Partner",
                                "children" = "Has Children",
                                "est_months_served_on_20220501" = "Time Served (months)",
                                "race_codeB" = "Black",
                                "cell" = "Shares a cell",
                                "unit_type_nolsgp-tc" = "Therapeutic Community (ref = General Population)",
                                "unit_type_nolsrec" = "Recovery (ref = General Population)",
                                "unit_type_nolshons" = "Honor (ref = General Population)",
                                "unit_type_nolsrhu" = "Restrictive Housing (ref = General Population)",
                                "unit_type_nolsthu" = "Transitional Housing (ref = General Population)"),
         custom.header=list("Institution" = 1,
                            "Subjective Severity" = 2),
         custom.model.names = c("(1)", "(2)"),
         digits=3,
         stars = c(0.001, 0.01, 0.05),
         column.spacing = 0,
         custom.note = "Notes: Standard errors in parentheses. %stars ",
         file=file.name)
}


```

# Exploratory factor analysis 

```{r Data Set up}
pcq2_cc <- pcq2_cc[,-which(names(pcq2_cc) %in% names(scale.hyp.key))]
pcq2_of <- pcq2_of[,-which(names(pcq2_of) %in% names(scale.hyp.key))]
```

```{r Parallel Analyses, include=FALSE}
# Assumes continuous data
# principal axis factoring: does not require the data to be multivariate normal. 

parallel_pw <- fa.parallel(pcq2, fm="pa", fa="both", sim=FALSE) # nfactors = 11
parallel_cc <- fa.parallel(pcq2_cc, fm="pa", fa="both", sim=FALSE) # nfactors = 11
parallel_of <- fa.parallel(pcq2_of, fm="pa", fa="both", sim=FALSE,  plot=FALSE) # nfactors = 8

tab <- data.frame(dataset = c("Pairwise",
                              "Missing Data Imputed",
                              "Complete Cases Only"),
                 observations = c(NA,
                                  nrow(pcq2_of),
                                  nrow(pcq2_cc)),
                 variables = c(ncol(pcq2),
                               ncol(pcq2_of),
                                  ncol(pcq2_cc)),
                 factors = c(parallel_pw$nfact,
                             parallel_of$nfact,
                             parallel_cc$nfact))
knitr::kable(tab)
```

```{r Factor Analysis, include=FALSE}

# To test function
# n_factors <- parallel_of$nfact
# data <- pcq2_of
# model.name <- "of"

# Code for factor analysis
fa_tab <- function(n_factors, data, model.name){
fa.results <- fa(r=data,  
                    nfactors = n_factors, 
                    fm="pa", 
                    rotate="oblimin",
                    impute = "none",
                    use = "pairwise", #treats missing data as pairwise 
                    warnings=TRUE,
                    missing=FALSE) # all datasets are set to cc or have already been imputed 

# Link factors to PCQ scales
# Using the scales of the question with the highest loading for this
temp <- data.frame(unclass(fa.results$loadings)) # Extract factor loadings
temp$question_qno <- rownames(temp)
temp <- left_join(temp, pcq_lookup[,c("question_qno", "question_no_pa_2022a","question_pa_2022a", "scale_theory")])
for(i in 1:n_factors){
  names(temp)[i] <- temp[which.max(abs(temp[,i])),"scale_theory"]
}
temp <- temp[,c((n_factors+1):ncol(temp),1:n_factors)] # Shuffle columns 

# Build Table 2 in Bosma 
# Retain only those values with more than .265 (Bosma uses .4, in our case, I feel safe in this institution is .29, and satisfaction with religious services loads at .269)

# Set up dataframe keep based on first factor
temp2 <- temp[,4+1] # Hard coded 
k <- which(abs(temp2)>.4)
keep <- data.frame(loading.value=temp[k,4+1],
                   factor=rep(names(temp)[4+1], length(k)),
                   question_no_pa_2022a=temp[k,"question_no_pa_2022a"],
                   question_pa_2022a=temp[k,"question_pa_2022a"])

# repeat for all other factors
if(n_factors>1){
for(i in 2:n_factors){
  temp2 <- temp[,4+i] 
  k <- which(abs(temp2)>.25)
  temp3 <- data.frame(loading.value=temp[k,4+i],
                      factor=rep(names(temp)[4+i], length(k)),
                      question_no_pa_2022a=temp[k,"question_no_pa_2022a"],
                      question_pa_2022a=temp[k,"question_pa_2022a"])
  keep <- rbind(keep, temp3)
}
}

# Check that a question loads onto the anticipated factor 
tab <- left_join(keep,pcq_lookup[which(pcq_lookup$question_qno %in% retain),c("question_pa_2022a", "factor_no_bosma")]) 
tab$loading.value <- as.numeric(tab$loading.value)
duplicated_items <- tab$question_pa_2022a[which(duplicated(tab$question_pa_2022a))]
# duplicated_items <- tab$question_pa_2022a[which(duplicated(tab[which(tab$loading.value>.4),"question_pa_2022a"]))]
if(length(duplicated_items>0)){
print(paste("The following items double loaded:", duplicated_items))
for(i in duplicated_items){
print(i)
print(tab[which(tab$question_pa_2022a==i),c("factor","loading.value")])
temp <- tab[which(tab$question_pa_2022a==i),c("factor","loading.value")]
temp <- temp[temp$loading.value == min(temp$loading.value),]
k <- which(tab$loading.value == temp$loading.value & tab$factor == temp$factor)
tab <- tab[-k,]
}
}

# Format table for output
tab <- tab[order(tab$factor_no_bosma),]
tab <- tab[,c("question_pa_2022a","factor","loading.value")]
names(tab) <- c("Item", paste0("Factor_",model.name), paste0("Loading_", model.name))
return(tab)
}

fa_tab_pw <- fa_tab(parallel_of$nfact, pcq2, "pw")
fa_tab_of <- fa_tab(parallel_of$nfact, pcq2_of, "of")
fa_tab_cc <- fa_tab(parallel_cc$nfact, pcq2_cc, "cc")

```

```{r Prepare data for factor analysis table, include = FALSE}
table.link <- data.frame(Factor_of = c("prisoners", "procedure", "safety", "visits", "visits.1","contact","sleep", "care", "shop", "actsat", "reint","actav","autonomy"),
                         Factor_pw = c("prisoners", "procedure", "safety", "visits", "visits.1","contact","sleep", "care", "shop", "actsat", "reint","actav","autonomy"),
                         Factor_cc = c("prisoners", "procedure", "safety", "visits", "visits.1","contact","sleep", "care", "shop", "actsat", "actav","reint","autonomy"),
                         factor_no_bosma = c(1,2,3,4,5,6,7,8,9,11,10,12,13),
                         Factor = c(1,2,3,4,5,6,7,8,9,10,11,12,13))

# Main paper 
keep <- pcq_lookup[which(pcq_lookup$question_qno %in% retain),c("scale_theory","factor_no_bosma","factor_loading_bosma","question_pa_2022a")]
names(keep)[which(names(keep)=="question_pa_2022a")] <- "Item"
keep$factor_no_bosma <- as.numeric(keep$factor_no_bosma)
keep <- left_join(keep, table.link[,c("factor_no_bosma", "Factor")])
keep <- keep[,-which(names(keep)=="factor_no_bosma")]
names(keep)[which(names(keep)=="Factor")] <- "factor_no_bosma"
fa_tab_of <- left_join(fa_tab_of, table.link[,c("Factor_of", "Factor")])
keep <- left_join(keep, fa_tab_of[,-which(names(fa_tab_of)=="Factor_of")])
names(keep)[which(names(keep)=="Factor")] <- "Factor_of"
fa_tab_pw <- left_join(fa_tab_pw, table.link[,c("Factor_pw", "Factor")])
keep <- left_join(keep, fa_tab_pw[,-which(names(fa_tab_pw)=="Factor_pw")])
names(keep)[which(names(keep)=="Factor")] <- "Factor_pw"
fa_tab_cc <- left_join(fa_tab_cc, table.link[,c("Factor_cc", "Factor")])
keep <- left_join(keep, fa_tab_cc[,c("Item","Factor", "Loading_cc")])
names(keep) <- c("Theory","LB", "Item","FB", "L1", "F1", "L2", "F2", "F3", "L3")
keep <- keep[,c("Item", "F1", "L1","F3","L3","F2","L2","FB", "LB")]
keep <- keep %>% arrange(F1)
```

```{r Print table, results='asis'}
knitr::kable(keep)

print(xtable(keep, digits=c(0,0,0,2,0,2,0,2,0,2), caption="Exploratory Factor Analysis"), 
      include.rownames = FALSE, 
      caption.placement="top",
      file = "output/tables/efa_all.txt")
```

```{r Prepare data for factor analysis table in appendix, include = FALSE}
# Appendix 
keep <- pcq_lookup[which(pcq_lookup$question_qno %in% retain),c("scale_theory","question_pa_2022a")]
names(keep)[which(names(keep)=="question_pa_2022a")] <- "Item"
fa_tab_cc <- left_join(fa_tab_cc, table.link[,c("Factor_cc", "Factor")])
keep <- left_join(keep, fa_tab_cc[,c("Item","Factor", "Loading_cc")])
names(keep)[which(names(keep)=="Factor")] <- "Factor_cc"
fa_tab_cc <- left_join(fa_tab_cc, table.link[,c("Factor_cc", "Factor")])
keep <- left_join(keep, fa_tab_cc[,c("Item","Factor", "Loading_cc")])
names(keep) <- c("Theory", "Item", "F1", "L1", "F2", "L2")
keep <- keep[,c("Item", "F1", "L1", "F2", "L2")]
```

```{r Print table appendix, results='asis'}
knitr::kable(keep)

print(xtable(keep, digits=c(0,0,0,2,0,2), caption="Exploratory Factor Analysis"), 
      include.rownames = FALSE, 
      caption.placement="top",
      file = "output/tables/efa_appendix.txt")
```
